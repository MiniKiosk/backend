import sounddevice as sd
import numpy as np
import torch
from transformers import WhisperProcessor, WhisperForConditionalGeneration
from sentence_transformers import SentenceTransformer, util
from transformers import WhisperProcessor, WhisperForConditionalGeneration
import sys
import re

# í•œê¸€ ìˆ˜ëŸ‰ ë§¤í•‘ (í•„ìš”ì‹œ ë” ì¶”ê°€ ê°€ëŠ¥)
KOREAN_NUM = {
    "í•œ": 1, "í•˜ë‚˜": 1,"ì•Šì•„":1,"ì•„ë‚˜":1,
    "ë‘": 2, "ë‘˜": 2,
    "ì„¸": 3, "ì…‹": 3,
    "ë„¤": 4, "ë„·": 4,
    "ë‹¤ì„¯": 5, "ì—¬ì„¯": 6, "ì¼ê³±": 7, "ì—¬ëŸ": 8, "ì•„í™‰": 9,
    "ì—´": 10
}

def extract_menus_with_quantity(text):
    orders = {}

    for menu in menu_list:
        if menu.startswith("ë¼ì§€"):
            keywords = ["ë¼ì§€"]
        elif menu.startswith("ë‚´ì¥"):
            keywords = ["ë‚´ì¥"]
        elif menu.startswith("ì„ì–´"):
            keywords = ["ì„ì–´"]
        elif menu.startswith("ìˆœëŒ€"):
            keywords = ["ìˆœëŒ€"]
        else:
            keywords = [menu]

        for keyword in keywords:
            if keyword in text:
                # ë©”ë‰´ ì•ë’¤ë¡œ ìˆ˜ëŸ‰ ì°¾ê¸°
                pattern = rf"{keyword}\s*([0-9]+|[ê°€-í£]+)?"
                match = re.search(pattern, text)
                if match:
                    qty_str = match.group(1)
                    if qty_str:
                        qty = KOREAN_NUM.get(qty_str, None)
                        if qty is None:
                            try:
                                qty = int(qty_str)
                            except:
                                qty = 1
                    else:
                        qty = 1
                else:
                    qty = 1
                orders[menu] = orders.get(menu, 0) + qty

    return orders


# âœ… Whisper ëª¨ë¸ ë³€ê²½ (OpenAI ê³µì‹)
processor = WhisperProcessor.from_pretrained("openai/whisper-small")
model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-small")

menu_list = ["ë¼ì§€êµ­ë°¥", "ë‚´ì¥êµ­ë°¥", "ì„ì–´êµ­ë°¥", "ìˆœëŒ€êµ­ë°¥"]
# ì˜¤ë””ì˜¤ ì •ê·œí™”
def normalize_audio(audio):
    return audio / np.max(np.abs(audio))

# ìŒì„± ë…¹ìŒ
def record_audio(duration=5, sample_rate=16000):
    print(f"ğŸ™ï¸ {duration}ì´ˆê°„ ë…¹ìŒ ì¤‘...")
    audio = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, dtype='float32')
    sd.wait()
    audio = audio.flatten()
    audio = normalize_audio(audio)
    print("âœ… ë…¹ìŒ ì™„ë£Œ.")
    return audio

# ìŒì„± â†’ í…ìŠ¤íŠ¸ ë³€í™˜
def speech_to_text(audio, sample_rate=16000):
    input_features = processor(audio, sampling_rate=sample_rate, return_tensors="pt").input_features
    generated_ids = model.generate(input_features)
    result = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
    return result.strip()

# ìœ ì‚¬ë„ ê¸°ë°˜ ë©”ë‰´ ì¶”ì¶œ
def extract_menus(text):
    found_menus = []

    for menu, embedding in zip(menu_list, menu_embeddings):
        score = util.cos_sim(similarity_model.encode(text, convert_to_tensor=True), embedding)[0].item()
        if score > 0.45:  # ì„ê³„ê°’ ì¡°ê¸ˆ ë‚®ì¶°ë„ ê°€ëŠ¥
            found_menus.append((menu, round(score, 2)))

    # ì¤‘ë³µ ë°©ì§€ ë° ì ìˆ˜ ì •ë ¬ (ì„ íƒ)
    found_menus.sort(key=lambda x: -x[1])
    return [menu for menu, _ in found_menus]

# ì£¼ë¬¸ ì²˜ë¦¬
def place_order(menu_dict):
    if menu_dict:
        for menu, qty in menu_dict.items():
            print(f"ğŸ§¾ ì£¼ë¬¸ ì™„ë£Œ: '{menu}' ë©”ë‰´ {qty}ê°œê°€ ì£¼ë¬¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("âš ï¸ ë©”ë‰´ë¥¼ ì •í™•íˆ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”.")

# ë©”ì¸ íë¦„
def main():
    while True:
        cmd = input("ğŸ§ Enter í‚¤ë¡œ ë…¹ìŒ / 'q' ì…ë ¥ ì‹œ ì¢…ë£Œ: ")
        if cmd.lower() == 'q':
            print("ğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        audio = record_audio(duration=5)
        text = speech_to_text(audio)
        print(f"ğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸: {text}")

        menu_dict = extract_menus_with_quantity(text)
        place_order(menu_dict)

if __name__ == "__main__":
    main()

